{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/link1697/crack_segmentation/blob/main/%E8%B4%A5%E5%8C%97_pytorch_2stage_resize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0XIhXe6te5RQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from keras import metrics\n",
        "import random\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tqdm import tqdm\n",
        "from keras import backend as K\n",
        "import torch.nn.functional as F\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZqHdhWGrDQb",
        "outputId": "6089c81d-e3bc-40da-9e9e-f984e3ffa195"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sMVi4NXNvmOg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_FvQ41b1e5RU"
      },
      "outputs": [],
      "source": [
        "def ensure_uint8(image):\n",
        "    if image.dtype != np.uint8:\n",
        "        image = (image * 255).clip(0, 255).astype(np.uint8)\n",
        "    return image\n",
        "\n",
        "def apply_gaussian_blur(image, kernel_size=(5, 5)):\n",
        "    # Assuming the input image is a float between 0 and 1\n",
        "    image = ensure_uint8(image)  # Convert to uint8\n",
        "    blurred = cv2.GaussianBlur(image, kernel_size, 0)\n",
        "    return blurred / 255.0  # Re-normalize to float between 0 and 1 if necessary\n",
        "\n",
        "def apply_sobel_filter(image, ksize=3):\n",
        "    # Convert to grayscale\n",
        "    image = ensure_uint8(image)  # Convert to uint8\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=ksize)\n",
        "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=ksize)\n",
        "    sobel = cv2.addWeighted(np.absolute(sobelx), 0.5, np.absolute(sobely), 0.5, 0)\n",
        "    sobel = np.clip(sobel, 0, 255).astype(np.uint8)  # Ensure the result is uint8\n",
        "    return cv2.cvtColor(sobel, cv2.COLOR_GRAY2BGR) / 255.0  # Convert back to BGR and normalize\n",
        "\n",
        "def apply_gaussian_noise(image, noise_level=5):\n",
        "    # Assuming the input image is a float between 0 and 1\n",
        "    image = ensure_uint8(image)  # Convert to uint8\n",
        "    gauss_noise = np.random.normal(0, noise_level, image.shape).astype(np.uint8)\n",
        "    noisy_image = cv2.add(image, gauss_noise)\n",
        "    return noisy_image / 255.0  # Re-normalize to float between 0 and 1 if necessary\n",
        "\n",
        "def color_distort_smooth(image, hue_shift=87, saturation_scale=1.3, value_scale=1.7):\n",
        "    # Assuming the input image is a float between 0 and 1\n",
        "    image = ensure_uint8(image)  # Convert to uint8\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    h, s, v = cv2.split(hsv)\n",
        "    h = (h + hue_shift) % 180\n",
        "    s = np.clip(s * saturation_scale, 0, 255).astype(np.uint8)\n",
        "    v = np.clip(v * value_scale, 0, 255).astype(np.uint8)\n",
        "    final_hsv = cv2.merge((h, s, v))\n",
        "    color_distorted_image = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "    return color_distorted_image / 255.0  # Re-normalize if necessary\n",
        "\n",
        "augmentations = [apply_gaussian_blur, apply_sobel_filter, apply_gaussian_noise, color_distort_smooth]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8OCDeLtqI6k"
      },
      "source": [
        "U-net + MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCsel6c0L2Y0",
        "outputId": "e567e43d-1b19-4f6c-9250-086df66a6750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Projected Output Shape: torch.Size([1, 64])\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# U-Net Encoder Blocks\n",
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "# U-Net Encoder Class\n",
        "class UNetEncoder(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=32):\n",
        "        super(UNetEncoder, self).__init__()\n",
        "        self.enc1 = conv_block(in_channels, features)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.enc2 = conv_block(features, features * 2)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.enc3 = conv_block(features * 2, features * 4)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        self.enc4 = conv_block(features * 4, features * 8)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Bottleneck layer\n",
        "        self.bottleneck = nn.Conv2d(features * 8, features * 16, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.enc1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.enc2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.enc3(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.enc4(x)\n",
        "        x = self.pool4(x)\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Flatten output\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "# Projection Head Class\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, output_dim=64):\n",
        "        super(ProjectionHead, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Integrate U-Net Encoder and Projection Head\n",
        "dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
        "encoder = UNetEncoder(in_channels=3, features=32).to(device)\n",
        "encoder_output = encoder(dummy_input)\n",
        "\n",
        "# Flattened encoder output size\n",
        "flattened_output = encoder_output.shape[1]\n",
        "\n",
        "# Create the projection head with the correct input dimension\n",
        "projection_head = ProjectionHead(input_dim=flattened_output).to(device)\n",
        "\n",
        "# Test the forward pass with a dummy input\n",
        "projected_output = projection_head(encoder_output)\n",
        "print(\"Projected Output Shape:\", projected_output.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meBcJ8ZjqLvu"
      },
      "source": [
        "train encoder+MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-ApsqLHp5Wy"
      },
      "source": [
        "Fine-tuning dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS7te2BqnNPY",
        "outputId": "823e99f8-d629-4481-d6fc-7effa012fe50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Adjusting train/test split to match dataset length (1695)\n",
            "Training Image Batch Shape: torch.Size([16, 3, 448, 448])\n",
            "Training Mask Batch Shape: torch.Size([16, 1, 448, 448])\n",
            "Testing Image Batch Shape: torch.Size([16, 3, 448, 448])\n",
            "Testing Mask Batch Shape: torch.Size([16, 1, 448, 448])\n"
          ]
        }
      ],
      "source": [
        "# Define a Dataset Class for Crack Images and Masks\n",
        "class CrackSegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "\n",
        "        # List all image files in the directory (assuming each has a corresponding mask)\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the image file name and corresponding mask file path\n",
        "        image_file = self.image_files[idx]\n",
        "        image_path = os.path.join(self.image_dir, image_file)\n",
        "        mask_path = os.path.join(self.mask_dir, image_file)  # Assuming masks have the same name\n",
        "\n",
        "        # Load the image and mask\n",
        "        image = cv2.imread(image_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Load mask as grayscale\n",
        "\n",
        "        # Normalize both to the range [0, 1] without resizing\n",
        "        image = image / 255.0  # Normalize image\n",
        "        mask = mask / 255.0  # Normalize mask\n",
        "\n",
        "        # Convert to PyTorch tensors and change shape to [C, H, W]\n",
        "        image_tensor = torch.tensor(image.transpose(2, 0, 1), dtype=torch.float32)\n",
        "        mask_tensor = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)  # Add a channel dimension\n",
        "\n",
        "        return image_tensor, mask_tensor\n",
        "\n",
        "\n",
        "# Ensure we use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Example Usage\n",
        "# Replace these paths with the appropriate directories containing your crack images and masks\n",
        "image_dir = './archive/crack_segmentation_dataset/test/images/'\n",
        "mask_dir = './archive/crack_segmentation_dataset/test/masks/'\n",
        "dataset = CrackSegmentationDataset(image_dir, mask_dir)\n",
        "\n",
        "# Check the total size of the dataset\n",
        "total_size = len(dataset)\n",
        "train_size = 300\n",
        "test_size = 200\n",
        "\n",
        "# Verify that the total matches your desired split\n",
        "if train_size + test_size != total_size:\n",
        "    print(f\"Warning: Adjusting train/test split to match dataset length ({total_size})\")\n",
        "    train_size = int(0.6 * total_size)  # Example: 60% for training\n",
        "    test_size = total_size - train_size\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders for training and testing\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "# Move batches to the appropriate device (GPU/CPU) for training set\n",
        "for image_batch, mask_batch in train_loader:\n",
        "    image_batch = image_batch.to(device)\n",
        "    mask_batch = mask_batch.to(device)\n",
        "    print(\"Training Image Batch Shape:\", image_batch.shape)\n",
        "    print(\"Training Mask Batch Shape:\", mask_batch.shape)\n",
        "    break\n",
        "\n",
        "# Move batches to the appropriate device (GPU/CPU) for testing set\n",
        "for image_batch, mask_batch in test_loader:\n",
        "    image_batch = image_batch.to(device)\n",
        "    mask_batch = mask_batch.to(device)\n",
        "    print(\"Testing Image Batch Shape:\", image_batch.shape)\n",
        "    print(\"Testing Mask Batch Shape:\", mask_batch.shape)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4QSglTUp2Sy"
      },
      "source": [
        "fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVCQZMNk7Tc7"
      },
      "source": [
        "用前面unet的encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYYxpZ93dSTU",
        "outputId": "30bd3654-8ddd-419b-8e32-1dffb21c1744"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ImprovedUNet(\n",
              "  (enc1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (enc2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (enc3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (enc4): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (bottleneck): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (dec4): DecoderBlock(\n",
              "    (attention_gate): AttentionGate(\n",
              "      (conv_gate): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_gate): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv_skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (upconv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (residual_block): ResidualBlock(\n",
              "      (projection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (dec3): DecoderBlock(\n",
              "    (attention_gate): AttentionGate(\n",
              "      (conv_gate): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_gate): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv_skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (upconv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (residual_block): ResidualBlock(\n",
              "      (projection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (dec2): DecoderBlock(\n",
              "    (attention_gate): AttentionGate(\n",
              "      (conv_gate): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_gate): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv_skip): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_skip): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (upconv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (residual_block): ResidualBlock(\n",
              "      (projection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (dec1): DecoderBlock(\n",
              "    (attention_gate): AttentionGate(\n",
              "      (conv_gate): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_gate): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv_skip): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_skip): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (upconv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (residual_block): ResidualBlock(\n",
              "      (projection): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Residual Block with Debugging\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, num_filters):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.projection = None\n",
        "        if in_channels != num_filters:\n",
        "            self.projection = nn.Conv2d(in_channels, num_filters, kernel_size=1, stride=1)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, num_filters, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_filters)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_filters)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(f\"Input shape to ResidualBlock: {x.shape}\")\n",
        "        shortcut = x\n",
        "        if self.projection:\n",
        "            shortcut = self.projection(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += shortcut\n",
        "        return self.relu(out)\n",
        "\n",
        "# Attention Gate\n",
        "class AttentionGate(nn.Module):\n",
        "    def __init__(self, skip_channels, gate_channels, out_channels):\n",
        "        super(AttentionGate, self).__init__()\n",
        "        # Match the number of channels correctly\n",
        "        self.conv_gate = nn.Conv2d(gate_channels, out_channels, kernel_size=1)\n",
        "        self.bn_gate = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv_skip = nn.Conv2d(skip_channels, out_channels, kernel_size=1)\n",
        "        self.bn_skip = nn.BatchNorm2d(out_channels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, skip, gate):\n",
        "        skip_resized = F.interpolate(skip, size=gate.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        # Adjust the gate and skip to have the same dimensions\n",
        "        gate_resized = self.conv_gate(gate)\n",
        "        gate_resized = self.bn_gate(gate_resized)\n",
        "        gate_resized = self.relu(gate_resized)\n",
        "\n",
        "        skip_resized = self.conv_skip(skip)\n",
        "        skip_resized = self.bn_skip(skip_resized)\n",
        "\n",
        "        # Combine the skip and gate tensors\n",
        "        attention = self.sigmoid(gate_resized + skip_resized)\n",
        "\n",
        "        # Multiply by the skip tensor\n",
        "        return skip * attention\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, skip_channels, out_channels):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        # Adjust attention gate to receive the correct number of input channels\n",
        "        self.attention_gate = AttentionGate(skip_channels, out_channels, out_channels)\n",
        "        # Upsample input channels to expected size\n",
        "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        # Ensure that the residual block receives the correct input channels\n",
        "        self.residual_block = ResidualBlock(out_channels + skip_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        #print(f\"Shape of x before upconv: {x.shape}\")\n",
        "        x = self.upconv(x)\n",
        "        #print(f\"Shape of x after upconv: {x.shape}\")\n",
        "\n",
        "        # Apply the attention gate to align the skip connection channels\n",
        "        skip = self.attention_gate(skip, x)\n",
        "        #print(f\"Shape of skip after attention gate: {skip.shape}\")\n",
        "\n",
        "        # Concatenate the skip connection and the upsampled feature map\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        #print(f\"Shape of x after concatenation: {x.shape}\")\n",
        "\n",
        "        # Pass through the residual block\n",
        "        x = self.residual_block(x)\n",
        "        #print(f\"Shape of x after residual block: {x.shape}\")\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# ImprovedUNet Model\n",
        "class ImprovedUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1, features=32):\n",
        "        super(ImprovedUNet, self).__init__()\n",
        "        self.enc1 = conv_block(in_channels, features)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.enc2 = conv_block(features, features * 2)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.enc3 = conv_block(features * 2, features * 4)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        self.enc4 = conv_block(features * 4, features * 8)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Bottleneck layer\n",
        "        self.bottleneck = nn.Conv2d(features * 8, features * 16, kernel_size=3, padding=1)   #padding =1 keeps feature map height & width unchanged\n",
        "\n",
        "        self.dec4 = DecoderBlock(features * 16, features * 8, features * 8)\n",
        "        self.dec3 = DecoderBlock(features * 8, features * 4, features * 4)\n",
        "        self.dec2 = DecoderBlock(features * 4, features * 2, features * 2)\n",
        "        self.dec1 = DecoderBlock(features * 2, features, features)\n",
        "\n",
        "        self.final = nn.Conv2d(features, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        #print(f\"Shape of enc1: {enc1.shape}\")\n",
        "        p1 = self.pool1(enc1)\n",
        "        enc2 = self.enc2(p1)\n",
        "        #print(f\"Shape of enc2: {enc2.shape}\")\n",
        "        p2 = self.pool2(enc2)\n",
        "        enc3 = self.enc3(p2)\n",
        "        #print(f\"Shape of enc3: {enc3.shape}\")\n",
        "        p3 = self.pool3(enc3)\n",
        "        enc4 = self.enc4(p3)\n",
        "        #print(f\"Shape of enc4: {enc4.shape}\")\n",
        "        p4 = self.pool4(enc4)\n",
        "\n",
        "        bottleneck = self.bottleneck(p4)\n",
        "        #print(f\"Shape of bottleneck: {bottleneck.shape}\")  #  expect 512, [batch_size, num_channels, height, width]-[16, 512, 7, 7]\n",
        "\n",
        "        dec4 = self.dec4(bottleneck, enc4)\n",
        "        #print(f\"Shape of dec4: {dec4.shape}\")\n",
        "        dec3 = self.dec3(dec4, enc3)\n",
        "        #print(f\"Shape of dec3: {dec3.shape}\")\n",
        "        dec2 = self.dec2(dec3, enc2)\n",
        "        #print(f\"Shape of dec2: {dec2.shape}\")\n",
        "        dec1 = self.dec1(dec2, enc1)\n",
        "        #print(f\"Shape of dec1: {dec1.shape}\")\n",
        "\n",
        "        final_output = torch.sigmoid(self.final(dec1))\n",
        "        #print(f\"Shape of final output: {final_output.shape}\")\n",
        "        return final_output\n",
        "\n",
        "\n",
        "\n",
        "# Model instantiation and device selection\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ImprovedUNet(in_channels=3, out_channels=1, features=32)\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJGc2E9e8peL"
      },
      "source": [
        "fine-tuning train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "aeWXEjQ7VX4f",
        "outputId": "ee0e7b73-79b7-4115-a6a4-e0ef590ccad5"
      },
      "outputs": [],
      "source": [
        "# Move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, masks in train_loader:\n",
        "            # Move images and masks to the GPU\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# Testing/Prediction function\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    masks = []\n",
        "    with torch.no_grad():\n",
        "        for images, gt in test_loader:   \n",
        "            # Move images to the GPU\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Apply thresholding to get binary predictions\n",
        "            # predicted_masks = (outputs > 0.5).float()\n",
        "\n",
        "            # Store predictions (back to CPU if necessary)\n",
        "            predictions.extend(outputs.cpu())\n",
        "            masks .extend(gt.cpu())\n",
        "\n",
        "            \n",
        "    return predictions, masks\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ImprovedUNet(\n",
              "  (enc1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (enc2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (enc3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (enc4): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (bottleneck): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (dec4): DecoderBlock(\n",
              "    (attention_gate): AttentionGate(\n",
              "      (conv_gate): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_gate): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv_skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (upconv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (residual_block): ResidualBlock(\n",
              "      (projection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (dec3): DecoderBlock(\n",
              "    (attention_gate): AttentionGate(\n",
              "      (conv_gate): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_gate): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv_skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (upconv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (residual_block): ResidualBlock(\n",
              "      (projection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (dec2): DecoderBlock(\n",
              "    (attention_gate): AttentionGate(\n",
              "      (conv_gate): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_gate): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv_skip): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_skip): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (upconv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (residual_block): ResidualBlock(\n",
              "      (projection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (dec1): DecoderBlock(\n",
              "    (attention_gate): AttentionGate(\n",
              "      (conv_gate): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_gate): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv_skip): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn_skip): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "    )\n",
              "    (upconv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (residual_block): ResidualBlock(\n",
              "      (projection): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the model or tensor onto the appropriate device\n",
        "model = torch.load('2stage_model_1.pth', map_location=device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_precision(true_positives, false_positives):\n",
        "    if true_positives + false_positives > 0:\n",
        "        return true_positives / (true_positives + false_positives)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def calculate_recall(true_positives, false_negatives):\n",
        "    if true_positives + false_negatives > 0:\n",
        "        return true_positives / (true_positives + false_negatives)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def calculate_dice(true_positives, false_positives, false_negatives):\n",
        "    if (2 * true_positives + false_positives + false_negatives) > 0:\n",
        "        return 2 * true_positives / (2 * true_positives + false_positives + false_negatives)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def compare(prediction_image, image_mask):\n",
        "    TP = np.sum((prediction_image == 1) & (image_mask == 1))\n",
        "    FP = np.sum((prediction_image == 1) & (image_mask == 0))\n",
        "    FN = np.sum((prediction_image == 0) & (image_mask == 1))\n",
        "    \n",
        "    precision = calculate_precision(TP, FP)\n",
        "    recall = calculate_recall(TP, FN)\n",
        "    dice = calculate_dice(TP, FP, FN)\n",
        "    print('precision, recall, dice: ', precision, recall, dice)\n",
        "    return precision, recall, dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    masks = []\n",
        "    for images, gt in tqdm(test_loader, desc='Evaluating', unit='batch'):  \n",
        "        # Move images to the GPU\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Apply thresholding to get binary predictions\n",
        "        # predicted_masks = (outputs > 0.5).float()\n",
        "\n",
        "        # Store predictions (back to CPU if necessary)\n",
        "        predictions.extend(outputs.cpu())\n",
        "        masks .extend(gt.cpu())\n",
        "        if len(masks) > 3:\n",
        "            break\n",
        "    \n",
        "            \n",
        "    return predictions, masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating:   0%|          | 0/43 [00:07<?, ?batch/s]\n"
          ]
        }
      ],
      "source": [
        "predicted_masks, origin_masks = evaluate_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xrGtPII2oZ5w"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.0070, 0.0057, 0.0052,  ..., 0.0117, 0.0106, 0.0113],\n",
              "          [0.0045, 0.0036, 0.0040,  ..., 0.0088, 0.0089, 0.0090],\n",
              "          [0.0051, 0.0038, 0.0017,  ..., 0.0122, 0.0070, 0.0070],\n",
              "          ...,\n",
              "          [0.0041, 0.0024, 0.0017,  ..., 0.0861, 0.0962, 0.0560],\n",
              "          [0.0045, 0.0025, 0.0020,  ..., 0.0567, 0.0439, 0.0287],\n",
              "          [0.0046, 0.0041, 0.0036,  ..., 0.0322, 0.0275, 0.0172]]],\n",
              "        grad_fn=<UnbindBackward0>),\n",
              " tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.9922, 0.0000, 0.0078],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 1.0000, 1.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.9922, 0.0078]]]))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_masks[0], origin_masks[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval(pred, label, thresholded=0.5):\n",
        "    p = copy.deepcopy(pred[0])\n",
        "    l = copy.deepcopy(label[0])\n",
        " \n",
        "    m = p > thresholded\n",
        "    p[m] = 1\n",
        "    p[~m] = 0\n",
        "    compare(p, l)\n",
        "    plt.imshow(p)\n",
        "    # plt.imshow(l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision, recall, dice:  0.3167655786350148 0.42235410484668645 0.3620178041543027\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "eval(predicted_masks[5].detach().numpy(), origin_masks[5].detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "XiEMu69eL4iY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision, recall, dice:  0 0 0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0, 0, 0)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare( predicted_masks[0].detach().numpy(), origin_masks[0].detach().numpy())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
